{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31027857",
   "metadata": {
    "executionInfo": {
     "elapsed": 3113,
     "status": "ok",
     "timestamp": 1746368395271,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "31027857"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal, interpolate\n",
    "from scipy.interpolate import CubicSpline\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import re\n",
    "from scipy.fft import fft\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy.signal import welch, hilbert\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import re\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "participant_id = 1 # Sofia data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "uYjhOCRB03fH",
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1746368397543,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "uYjhOCRB03fH"
   },
   "outputs": [],
   "source": [
    "def plot_single(all_data, n_samples=5000):\n",
    "    \"\"\"Plot single signal with seaborn styling.\"\"\"\n",
    "    # Apply seaborn-style settings\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    col1_name = all_data.columns[0]\n",
    "    col2_name = all_data.columns[1]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    axes[0].plot(all_data[col1_name].iloc[:n_samples],\n",
    "                label=f'{col1_name}',\n",
    "                linewidth=2,\n",
    "                alpha=0.8)\n",
    "    axes[0].set_title(f'Signal: {col1_name}', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Samples', fontsize=12)\n",
    "    axes[0].set_ylabel('Amplitude', fontsize=12)\n",
    "    axes[0].legend(frameon=True, fancybox=True, shadow=True)\n",
    "    axes[0].grid(True, linestyle='-', alpha=0.2, color='gray')\n",
    "\n",
    "    axes[1].plot(all_data[col2_name].iloc[:n_samples],\n",
    "                label=f'{col2_name}',\n",
    "                linewidth=2,\n",
    "                alpha=0.8)\n",
    "    axes[1].set_title(f'Signal: {col2_name}', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Samples', fontsize=12)\n",
    "    axes[1].set_ylabel('Amplitude', fontsize=12)\n",
    "    axes[1].legend(frameon=True, fancybox=True, shadow=True)\n",
    "    axes[1].grid(True, linestyle='-', alpha=0.2, color='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def plot_signals(all_data, vertical_raw_col='vertical_value', vertical_filtered_col='vertical_filtered', vertical_smoothed_col=None,\n",
    "                 horizontal_raw_col='horizontal_value', horizontal_filtered_col='horizontal_filtered', horizontal_smoothed_col=None, n_samples=5000):\n",
    "    \"\"\"Plot signals with seaborn styling.\"\"\"\n",
    "    # Apply seaborn-style settings\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    axes[0].plot(all_data[vertical_raw_col].iloc[:n_samples],\n",
    "                label='Original Vertical',\n",
    "                linewidth=2,\n",
    "                alpha=0.7)\n",
    "    axes[0].plot(all_data[vertical_filtered_col].iloc[:n_samples],\n",
    "                label='Filtered Vertical',\n",
    "                linewidth=2.5,\n",
    "                alpha=0.9)\n",
    "\n",
    "    if vertical_smoothed_col is not None:\n",
    "        axes[0].plot(all_data[vertical_smoothed_col].iloc[:n_samples],\n",
    "                    label='Smoothed Vertical',\n",
    "                    linewidth=2.5,\n",
    "                    alpha=0.9)\n",
    "\n",
    "    axes[0].set_title('Vertical Signal: Original vs Filtered', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Samples', fontsize=12)\n",
    "    axes[0].set_ylabel('Amplitude', fontsize=12)\n",
    "    axes[0].legend(frameon=True, fancybox=True, shadow=True)\n",
    "    axes[0].grid(True, linestyle='-', alpha=0.2, color='gray')\n",
    "\n",
    "    axes[1].plot(all_data[horizontal_raw_col].iloc[:n_samples],\n",
    "                label='Original Horizontal',\n",
    "                linewidth=2,\n",
    "                alpha=0.7)\n",
    "    axes[1].plot(all_data[horizontal_filtered_col].iloc[:n_samples],\n",
    "                label='Filtered Horizontal',\n",
    "                linewidth=2.5,\n",
    "                alpha=0.9)\n",
    "\n",
    "    if horizontal_smoothed_col is not None:\n",
    "        axes[1].plot(all_data[horizontal_smoothed_col].iloc[:n_samples],\n",
    "                    label='Smoothed Horizontal',\n",
    "                    linewidth=2.5,\n",
    "                    alpha=0.9)\n",
    "\n",
    "    axes[1].set_title('Horizontal Signal: Original vs Filtered', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Samples', fontsize=12)\n",
    "    axes[1].set_ylabel('Amplitude', fontsize=12)\n",
    "    axes[1].legend(frameon=True, fancybox=True, shadow=True)\n",
    "    axes[1].grid(True, linestyle='-', alpha=0.2, color='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def plot_filter_response(sos, worN=1500, filter_type=None, cutoff_freq=None, bw=None, fs=2.0):\n",
    "    \"\"\"Plot filter response with seaborn styling.\"\"\"\n",
    "    # Apply seaborn-style settings\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    w, h = signal.sosfreqz(sos, worN=worN)\n",
    "    w_normalized = w / np.pi\n",
    "    freq = w_normalized * (fs/2)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    db = 20 * np.log10(np.maximum(np.abs(h), 1e-10))\n",
    "    min_db = np.floor(np.min(db) / 10) * 10\n",
    "    max_db = np.ceil(np.max(db) / 10) * 10\n",
    "\n",
    "    if max_db - min_db < 40:\n",
    "        min_db = max_db - 40\n",
    "\n",
    "    ax1.plot(freq, db, linewidth=2.5, alpha=0.9)\n",
    "    ax1.set_ylim([min_db, max_db + 5])\n",
    "\n",
    "    db_range = max_db - min_db\n",
    "    if db_range <= 60:\n",
    "        step = 10\n",
    "    elif db_range <= 120:\n",
    "        step = 20\n",
    "    else:\n",
    "        step = 40\n",
    "    db_ticks = np.arange(min_db, max_db + step, step)\n",
    "    ax1.set_yticks(db_ticks)\n",
    "\n",
    "    if filter_type and cutoff_freq is not None:\n",
    "        if filter_type.lower() in ['lowpass', 'highpass']:\n",
    "            cutoff = cutoff_freq\n",
    "            ax1.axvline(x=cutoff, color='red', linestyle='--', linewidth=2, alpha=0.8,\n",
    "                         label=f'Cutoff: {cutoff:.2f} Hz')\n",
    "            ax1.plot(cutoff, -3, 'o', color='red', markersize=8)\n",
    "            ax1.annotate('-3 dB', xy=(cutoff, -3), xytext=(cutoff+0.05*(fs/2), -3+5),\n",
    "                        arrowprops=dict(arrowstyle='->', color='#333333',\n",
    "                                      connectionstyle='arc3,rad=0.1',\n",
    "                                      shrink=0.05, lw=1.5),\n",
    "                        fontsize=11, fontweight='bold', color='#333333')\n",
    "        elif filter_type.lower() in ['bandpass', 'bandstop']:\n",
    "            if isinstance(cutoff_freq, (list, tuple)) and len(cutoff_freq) == 2:\n",
    "                low, high = cutoff_freq\n",
    "                ax1.axvline(x=low, color='red', linestyle='--', linewidth=2, alpha=0.8,\n",
    "                             label=f'Lower cutoff: {low:.2f} Hz')\n",
    "                ax1.axvline(x=high, color='green', linestyle='--', linewidth=2, alpha=0.8,\n",
    "                             label=f'Upper cutoff: {high:.2f} Hz')\n",
    "                ax1.plot([low, high], [-3, -3], 'o', color='red', markersize=8)\n",
    "                ax1.annotate('-3 dB', xy=(low, -3), xytext=(low-0.15*(fs/2), -3+5),\n",
    "                            arrowprops=dict(arrowstyle='->', color='#333333',\n",
    "                                          connectionstyle='arc3,rad=0.1',\n",
    "                                          shrink=0.05, lw=1.5),\n",
    "                            fontsize=11, fontweight='bold', color='#333333')\n",
    "                ax1.annotate('-3 dB', xy=(high, -3), xytext=(high+0.05*(fs/2), -3+5),\n",
    "                            arrowprops=dict(arrowstyle='->', color='#333333',\n",
    "                                          connectionstyle='arc3,rad=0.1',\n",
    "                                          shrink=0.05, lw=1.5),\n",
    "                            fontsize=11, fontweight='bold', color='#333333')\n",
    "                if filter_type.lower() == 'bandpass':\n",
    "                    ax1.axvspan(low, high, alpha=0.15, color='green')\n",
    "                else:\n",
    "                    ax1.axvspan(0, low, alpha=0.15, color='green')\n",
    "                    ax1.axvspan(high, fs/2, alpha=0.15, color='green')\n",
    "            else:\n",
    "                print(\"For bandpass/bandstop filters, provide cutoff_freq as [low, high]\")\n",
    "\n",
    "    ax1.grid(True, which='both', linestyle='-', alpha=0.2, color='gray')\n",
    "    ax1.set_ylabel('Magnitude [dB]', fontsize=12)\n",
    "    if fs == 2.0:\n",
    "        ax1.set_xlabel('Normalized frequency (1.0 = Nyquist)', fontsize=12)\n",
    "    else:\n",
    "        ax1.set_xlabel('Frequency [Hz]', fontsize=12)\n",
    "\n",
    "    title = 'Filter Frequency Response'\n",
    "    if filter_type:\n",
    "        title = f'{filter_type.capitalize()} Filter Frequency Response'\n",
    "        if filter_type.lower() in ['lowpass', 'highpass'] and cutoff_freq is not None:\n",
    "            title += f\" (Cutoff: {cutoff_freq:.2f} Hz)\"\n",
    "        elif filter_type.lower() in ['bandpass', 'bandstop'] and isinstance(cutoff_freq, (list, tuple)):\n",
    "            title += f\" (Cutoffs: {cutoff_freq[0]:.2f}-{cutoff_freq[1]:.2f} Hz)\"\n",
    "    ax1.set_title(title, fontsize=14, fontweight='bold')\n",
    "    if filter_type:\n",
    "        ax1.legend(loc='best', frameon=True, fancybox=True, shadow=True)\n",
    "\n",
    "    phase = np.unwrap(np.angle(h))\n",
    "    ax2.plot(freq, phase, linewidth=2.5, alpha=0.9)\n",
    "    ax2.grid(True, which='both', linestyle='-', alpha=0.2, color='gray')\n",
    "    ax2.set_ylabel('Phase [rad]', fontsize=12)\n",
    "    if fs == 2.0:\n",
    "        ax2.set_xlabel('Normalized frequency (1.0 = Nyquist)', fontsize=12)\n",
    "    else:\n",
    "        ax2.set_xlabel('Frequency [Hz]', fontsize=12)\n",
    "\n",
    "    phase_ticks = [-np.pi, -0.5*np.pi, 0, 0.5*np.pi, np.pi]\n",
    "    phase_labels = [r'$-\\pi$', r'$-\\pi/2$', '0', r'$\\pi/2$', r'$\\pi$']\n",
    "    ax2.set_yticks(phase_ticks)\n",
    "    ax2.set_yticklabels(phase_labels)\n",
    "\n",
    "    x_limits = [0, fs/2]\n",
    "    ax1.set_xlim(x_limits)\n",
    "    ax2.set_xlim(x_limits)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bOo9hIO07lDF",
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1746368398538,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "bOo9hIO07lDF"
   },
   "outputs": [],
   "source": [
    "def plot_signals_interactive(all_data,\n",
    "                             vertical_raw_col='vertical_value',\n",
    "                             vertical_filtered_col='vertical_filtered',\n",
    "                             vertical_smoothed_col=None,\n",
    "                             horizontal_raw_col='horizontal_value',\n",
    "                             horizontal_filtered_col='horizontal_filtered',\n",
    "                             horizontal_smoothed_col=None,\n",
    "                             n_samples=5000,\n",
    "                             title='Signal Comparison'):\n",
    "    \"\"\"Plot signals with seaborn styling.\"\"\"\n",
    "    # Set seaborn style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "    n_samples = min(n_samples, len(all_data))\n",
    "    data_subset = all_data.iloc[:n_samples]\n",
    "    x_axis = data_subset.index if isinstance(data_subset.index, pd.DatetimeIndex) else np.arange(n_samples)\n",
    "    x_title = 'Time' if isinstance(data_subset.index, pd.DatetimeIndex) else 'Samples'\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    fig.suptitle(title, fontsize=16, y=0.98)\n",
    "\n",
    "    # Plot vertical signals\n",
    "    ax1.set_title('Vertical Signal Comparison', fontsize=14, pad=10)\n",
    "    if vertical_raw_col in data_subset.columns:\n",
    "        ax1.plot(x_axis, data_subset[vertical_raw_col],\n",
    "                 label='Raw Vertical')\n",
    "\n",
    "    if vertical_filtered_col in data_subset.columns:\n",
    "        ax1.plot(x_axis, data_subset[vertical_filtered_col],\n",
    "                 label='Filtered Vertical')\n",
    "\n",
    "    if vertical_smoothed_col is not None and vertical_smoothed_col in data_subset.columns:\n",
    "        ax1.plot(x_axis, data_subset[vertical_smoothed_col],\n",
    "                 label='Smoothed Vertical')\n",
    "\n",
    "    ax1.set_ylabel('Amplitude', fontsize=12)\n",
    "    ax1.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Set x-axis limits to match the data range exactly\n",
    "    ax1.set_xlim(x_axis[0], x_axis[-1])\n",
    "\n",
    "    # Plot horizontal signals\n",
    "    ax2.set_title('Horizontal Signal Comparison', fontsize=14, pad=10)\n",
    "    if horizontal_raw_col in data_subset.columns:\n",
    "        ax2.plot(x_axis, data_subset[horizontal_raw_col],\n",
    "                 label='Raw Horizontal')\n",
    "\n",
    "    if horizontal_filtered_col in data_subset.columns:\n",
    "        ax2.plot(x_axis, data_subset[horizontal_filtered_col],\n",
    "                 label='Filtered Horizontal')\n",
    "\n",
    "    if horizontal_smoothed_col is not None and horizontal_smoothed_col in data_subset.columns:\n",
    "        ax2.plot(x_axis, data_subset[horizontal_smoothed_col],\n",
    "                 label='Smoothed Horizontal')\n",
    "\n",
    "    ax2.set_xlabel(x_title, fontsize=12)\n",
    "    ax2.set_ylabel('Amplitude', fontsize=12)\n",
    "    ax2.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Set x-axis limits to match the data range exactly\n",
    "    ax2.set_xlim(x_axis[0], x_axis[-1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close()  # Close the figure to prevent double display\n",
    "    return fig\n",
    "\n",
    "def plot_fft_vertical_horizontal(vertical_value, horizontal_value, fs=1000, freq_limit=100):\n",
    "    \"\"\"Plot FFT with seaborn styling.\"\"\"\n",
    "    # Set seaborn style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "    if isinstance(vertical_value, pd.Series):\n",
    "        vertical_value = vertical_value.values\n",
    "    if isinstance(horizontal_value, pd.Series):\n",
    "        horizontal_value = horizontal_value.values\n",
    "\n",
    "    vertical_value_centered = vertical_value - np.mean(vertical_value)\n",
    "    horizontal_value_centered = horizontal_value - np.mean(horizontal_value)\n",
    "\n",
    "    N = len(vertical_value_centered)\n",
    "    if N == 0:\n",
    "        print(\"Warning: Input data has zero length.\")\n",
    "        return None\n",
    "\n",
    "    if len(horizontal_value_centered) != N:\n",
    "        raise ValueError(\"Vertical and horizontal signals must have the same length.\")\n",
    "\n",
    "    vertical_fft = np.fft.fft(vertical_value_centered)\n",
    "    horizontal_fft = np.fft.fft(horizontal_value_centered)\n",
    "\n",
    "    frequencies = np.fft.fftfreq(N, 1/fs)\n",
    "\n",
    "    positive_freq_mask = frequencies >= 0\n",
    "    positive_frequencies = frequencies[positive_freq_mask]\n",
    "    vertical_fft_positive = vertical_fft[positive_freq_mask]\n",
    "    horizontal_fft_positive = horizontal_fft[positive_freq_mask]\n",
    "\n",
    "    actual_freq_limit = min(freq_limit, positive_frequencies.max())\n",
    "    limited_indices = positive_frequencies <= actual_freq_limit\n",
    "\n",
    "    positive_frequencies_limited = positive_frequencies[limited_indices]\n",
    "    vertical_magnitude_limited = np.abs(vertical_fft_positive[limited_indices])\n",
    "    horizontal_magnitude_limited = np.abs(horizontal_fft_positive[limited_indices])\n",
    "\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    fig.suptitle(f'FFT Analysis (fs={fs} Hz)', fontsize=16, y=0.98)\n",
    "\n",
    "    # Plot vertical FFT\n",
    "    ax1.plot(positive_frequencies_limited, vertical_magnitude_limited,\n",
    "             linewidth=2.5, color='#1f77b4')\n",
    "    ax1.set_title(f'FFT of Vertical Signal (Centered, 0-{actual_freq_limit:.1f}Hz)',\n",
    "                  fontsize=14, pad=10)\n",
    "    ax1.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "    ax1.set_ylabel('Magnitude', fontsize=12)\n",
    "    ax1.set_xlim(0, actual_freq_limit)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add tight x-axis limits\n",
    "    if len(positive_frequencies_limited) > 0:\n",
    "        ax1.set_xlim(positive_frequencies_limited[0], positive_frequencies_limited[-1])\n",
    "\n",
    "    # Plot horizontal FFT\n",
    "    ax2.plot(positive_frequencies_limited, horizontal_magnitude_limited,\n",
    "             linewidth=2.5, color='#ff7f0e')\n",
    "    ax2.set_title(f'FFT of Horizontal Signal (Centered, 0-{actual_freq_limit:.1f}Hz)',\n",
    "                  fontsize=14, pad=10)\n",
    "    ax2.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "    ax2.set_ylabel('Magnitude', fontsize=12)\n",
    "    ax2.set_xlim(0, actual_freq_limit)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add tight x-axis limits\n",
    "    if len(positive_frequencies_limited) > 0:\n",
    "        ax2.set_xlim(positive_frequencies_limited[0], positive_frequencies_limited[-1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close()  # Close the figure to prevent double display\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c4da69",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746368399721,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "90c4da69"
   },
   "outputs": [],
   "source": [
    "def get_csv_for_participant(participant_id: int, dir):\n",
    "    files = os.listdir(dir)\n",
    "    filtered_files = [\n",
    "        file for file in files\n",
    "        if file.endswith('.csv') and f'participant_{participant_id}' in file\n",
    "    ]\n",
    "    sorted_files = sorted(filtered_files, key=lambda x: int(x.split('_')[1].replace('session', '')))\n",
    "    return sorted_files\n",
    "\n",
    "def downsample_signal(signal, original_fs, target_fs):\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    return signal.resample(signal, num_samples)\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    if low <= 0 or high >= 1 or low >= high:\n",
    "        raise ValueError(\"Invalid bandpass frequencies.\")\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def extract_features_for_prediction(eog_horizontal, eog_vertical, window_size=250, step=50):\n",
    "    features = []\n",
    "\n",
    "    for start_idx in range(0, len(eog_horizontal) - window_size + 1, step):\n",
    "        segment_h = eog_horizontal[start_idx:start_idx+window_size]\n",
    "        segment_v = eog_vertical[start_idx:start_idx+window_size]\n",
    "\n",
    "        peak_duration_h = np.abs(np.argmax(segment_h) - np.argmin(segment_h))\n",
    "        peak_duration_v = np.abs(np.argmax(segment_v) - np.argmin(segment_v))\n",
    "        amplitude_ratio_h = np.max(segment_h) / np.min(segment_h) if np.min(segment_h) != 0 else 0\n",
    "        amplitude_ratio_v = np.max(segment_v) / np.min(segment_v) if np.min(segment_v) != 0 else 0\n",
    "        velocity_h = np.max(np.abs(np.gradient(segment_h)))\n",
    "        velocity_v = np.max(np.abs(np.gradient(segment_v)))\n",
    "        acceleration_h = np.max(np.abs(np.gradient(np.gradient(segment_h))))\n",
    "        acceleration_v = np.max(np.abs(np.gradient(np.gradient(segment_v))))\n",
    "        freq_h = np.fft.fftfreq(len(segment_h))\n",
    "        psd_h = np.abs(fft(segment_h))**2\n",
    "        psd_v = np.abs(fft(segment_v))**2\n",
    "        dominant_freq_h = freq_h[np.argmax(psd_h)]\n",
    "        dominant_freq_v = freq_h[np.argmax(psd_v)]\n",
    "        skewness_h = skew(segment_h)\n",
    "        skewness_v = skew(segment_v)\n",
    "        kurtosis_h = kurtosis(segment_h)\n",
    "        kurtosis_v = kurtosis(segment_v)\n",
    "        entropy_h = -np.sum(np.histogram(segment_h, bins=20, density=True)[0] * np.log(np.histogram(segment_h, bins=20, density=True)[0] + 1e-9))\n",
    "        entropy_v = -np.sum(np.histogram(segment_v, bins=20, density=True)[0] * np.log(np.histogram(segment_v, bins=20, density=True)[0] + 1e-9))\n",
    "        peak_to_peak_h = np.ptp(segment_h)\n",
    "        peak_to_peak_v = np.ptp(segment_v)\n",
    "        zero_crossings_h = np.count_nonzero(np.diff(np.sign(segment_h)))\n",
    "        zero_crossings_v = np.count_nonzero(np.diff(np.sign(segment_v)))\n",
    "        rms_h = np.sqrt(np.mean(np.square(segment_h)))\n",
    "        rms_v = np.sqrt(np.mean(np.square(segment_v)))\n",
    "        slope_h = segment_h[-1] - segment_h[0]\n",
    "        slope_v = segment_v[-1] - segment_v[0]\n",
    "        derivative_h = np.gradient(segment_h).mean()\n",
    "        derivative_v = np.gradient(segment_v).mean()\n",
    "\n",
    "        features.append([\n",
    "            peak_duration_h, peak_duration_v, amplitude_ratio_h, amplitude_ratio_v,\n",
    "            velocity_h, velocity_v, acceleration_h, acceleration_v,\n",
    "            dominant_freq_h, dominant_freq_v, skewness_h, skewness_v,\n",
    "            kurtosis_h, kurtosis_v, entropy_h, entropy_v,\n",
    "            peak_to_peak_h, peak_to_peak_v, zero_crossings_h, zero_crossings_v,\n",
    "            rms_h, rms_v, slope_h, slope_v, derivative_h, derivative_v\n",
    "        ])\n",
    "\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yKaQxtvkBoPm",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746368402070,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "yKaQxtvkBoPm"
   },
   "outputs": [],
   "source": [
    "PARTICIPANT = 1\n",
    "BASE_PATH = \"/content/drive/MyDrive/Thesis/Code/Thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6639793",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746368405389,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "a6639793",
    "outputId": "eb234323-028f-47fb-ff30-e0e655b8bb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_1_participant_1_20250327_105914.csv', 'session_2_participant_1_20250327_111452.csv', 'session_3_participant_1_20250327_112708.csv', 'session_4_participant_1_20250327_113821.csv', 'session_5_participant_1_20250327_130157.csv', 'session_6_participant_1_20250327_132415.csv']\n"
     ]
    }
   ],
   "source": [
    "csv_files_for_participant = get_csv_for_participant(participant_id, BASE_PATH)\n",
    "print(csv_files_for_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WXvd1OmlBul9",
   "metadata": {
    "id": "WXvd1OmlBul9"
   },
   "outputs": [],
   "source": [
    "default_fill_value = 2.5\n",
    "\n",
    "processed_dfs = []\n",
    "for file in get_csv_for_participant(PARTICIPANT, BASE_PATH):\n",
    "    df = pd.read_csv(BASE_PATH + file)\n",
    "    df[\"corrected_timestamp\"] = pd.to_datetime(df[\"timestamp\"] + 3600, unit=\"s\", errors='coerce')\n",
    "    df.dropna(subset=[\"corrected_timestamp\"], inplace=True)\n",
    "    df = df.drop_duplicates(subset=[\"corrected_timestamp\"], keep='first')\n",
    "    df.sort_values(\"corrected_timestamp\", inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # Deduce frequency from the data\n",
    "    file_start_ts = df[\"corrected_timestamp\"].iloc[0]\n",
    "    file_end_ts = df[\"corrected_timestamp\"].iloc[-1]\n",
    "    file_points = len(df)\n",
    "\n",
    "    # Calculate the time span and deduce frequency\n",
    "    time_span = file_end_ts - file_start_ts\n",
    "    if file_points > 1:\n",
    "        # Calculate frequency based on number of samples and time span\n",
    "        # Frequency = (number of samples - 1) / time span\n",
    "        freq_hz = (file_points - 1) / time_span.total_seconds()\n",
    "\n",
    "        # Convert to appropriate time unit and create frequency string\n",
    "        if freq_hz >= 1000:\n",
    "            frequency = f'{int(round(1000/freq_hz))}us'  # microseconds\n",
    "        elif freq_hz >= 1:\n",
    "            frequency = f'{int(round(1000/freq_hz))}ms'  # milliseconds\n",
    "        else:\n",
    "            frequency = f'{int(round(1/freq_hz))}s'  # seconds\n",
    "    else:\n",
    "        # Default to 1ms if only one data point\n",
    "        frequency = '1ms'\n",
    "\n",
    "    freq_delta = pd.Timedelta(frequency)\n",
    "\n",
    "    # Create ideal index based on deduced frequency\n",
    "    ideal_index = pd.date_range(start=file_start_ts, periods=file_points, freq=frequency)\n",
    "\n",
    "    df.set_index(\"corrected_timestamp\", inplace=True)\n",
    "\n",
    "    reindexed_df = df.drop(columns=[\"timestamp\"], errors='ignore').reindex(ideal_index, method='nearest')\n",
    "    reindexed_df.index.name = \"timestamp\"\n",
    "\n",
    "    # Store the frequency with the dataframe for later use\n",
    "    reindexed_df.attrs['frequency'] = frequency\n",
    "    reindexed_df.attrs['freq_delta'] = freq_delta\n",
    "\n",
    "    processed_dfs.append(reindexed_df)\n",
    "\n",
    "if not processed_dfs:\n",
    "    raw_data = pd.DataFrame()\n",
    "    raw_data.index = pd.to_datetime([])\n",
    "    raw_data.index.name = \"timestamp\"\n",
    "else:\n",
    "    processed_dfs.sort(key=lambda d: d.index.min())\n",
    "\n",
    "    final_concat_list = [processed_dfs[0]]\n",
    "    cols = processed_dfs[0].columns\n",
    "\n",
    "    for i in range(len(processed_dfs) - 1):\n",
    "        df_prev = processed_dfs[i]\n",
    "        df_next = processed_dfs[i+1]\n",
    "\n",
    "        last_timestamp_prev = df_prev.index.max()\n",
    "        first_timestamp_next = df_next.index.min()\n",
    "\n",
    "        # Use the frequency from the previous dataframe for gap filling\n",
    "        freq_delta_prev = df_prev.attrs['freq_delta']\n",
    "        frequency_prev = df_prev.attrs['frequency']\n",
    "\n",
    "        gap_start_time = last_timestamp_prev + freq_delta_prev\n",
    "        gap_end_time = first_timestamp_next - freq_delta_prev\n",
    "\n",
    "        if gap_start_time <= gap_end_time:\n",
    "            gap_index = pd.date_range(start=gap_start_time, end=gap_end_time, freq=frequency_prev)\n",
    "            if not gap_index.empty:\n",
    "                gap_df = pd.DataFrame(default_fill_value, index=gap_index, columns=cols)\n",
    "                final_concat_list.append(gap_df)\n",
    "\n",
    "        final_concat_list.append(df_next)\n",
    "\n",
    "    raw_data = pd.concat(final_concat_list)\n",
    "\n",
    "final_concat_list = None\n",
    "# processed_dfs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5s5pCWqzOWE",
   "metadata": {
    "executionInfo": {
     "elapsed": 13071,
     "status": "ok",
     "timestamp": 1746368422917,
     "user": {
      "displayName": "Nicolas Gutierrez",
      "userId": "09420647906212853880"
     },
     "user_tz": -120
    },
    "id": "b5s5pCWqzOWE"
   },
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/Thesis/Code/Thesis/\"\n",
    "default_fill_value = 2.5\n",
    "frequency = '1ms'\n",
    "freq_delta = pd.Timedelta(frequency)\n",
    "\n",
    "processed_dfs = []\n",
    "for file in csv_files_for_participant:\n",
    "    df = pd.read_csv(base_path + file)\n",
    "    df[\"corrected_timestamp\"] = pd.to_datetime(df[\"timestamp\"] + 3600, unit=\"s\", errors='coerce')\n",
    "    df.dropna(subset=[\"corrected_timestamp\"], inplace=True)\n",
    "    df = df.drop_duplicates(subset=[\"corrected_timestamp\"], keep='first')\n",
    "    df.sort_values(\"corrected_timestamp\", inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    file_start_ts = df[\"corrected_timestamp\"].iloc[0]\n",
    "    file_points = len(df)\n",
    "\n",
    "    ideal_index = pd.date_range(start=file_start_ts, periods=file_points, freq=frequency)\n",
    "\n",
    "    df.set_index(\"corrected_timestamp\", inplace=True)\n",
    "\n",
    "    reindexed_df = df.drop(columns=[\"timestamp\"], errors='ignore').reindex(ideal_index, method='nearest')\n",
    "    reindexed_df.index.name = \"timestamp\"\n",
    "\n",
    "    processed_dfs.append(reindexed_df)\n",
    "\n",
    "if not processed_dfs:\n",
    "    raw_data = pd.DataFrame()\n",
    "    raw_data.index = pd.to_datetime([])\n",
    "    raw_data.index.name = \"timestamp\"\n",
    "else:\n",
    "    processed_dfs.sort(key=lambda d: d.index.min())\n",
    "\n",
    "    final_concat_list = [processed_dfs[0]]\n",
    "    cols = processed_dfs[0].columns\n",
    "\n",
    "    for i in range(len(processed_dfs) - 1):\n",
    "        df_prev = processed_dfs[i]\n",
    "        df_next = processed_dfs[i+1]\n",
    "\n",
    "        last_timestamp_prev = df_prev.index.max()\n",
    "        first_timestamp_next = df_next.index.min()\n",
    "\n",
    "        gap_start_time = last_timestamp_prev + freq_delta\n",
    "        gap_end_time = first_timestamp_next - freq_delta\n",
    "\n",
    "        if gap_start_time <= gap_end_time:\n",
    "            gap_index = pd.date_range(start=gap_start_time, end=gap_end_time, freq=frequency)\n",
    "            if not gap_index.empty:\n",
    "                gap_df = pd.DataFrame(default_fill_value, index=gap_index, columns=cols)\n",
    "                final_concat_list.append(gap_df)\n",
    "\n",
    "        final_concat_list.append(df_next)\n",
    "\n",
    "    raw_data = pd.concat(final_concat_list)\n",
    "\n",
    "final_concat_list = None\n",
    "# processed_dfs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_parquet(f\"data/{PARTICIPANT}_processed_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "021b0518"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
